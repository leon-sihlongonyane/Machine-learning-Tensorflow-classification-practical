{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyfJmkeKRpaC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs3Vxo5dmP7j"
      },
      "source": [
        "## Classification practical\n",
        "\n",
        "Total marks: 21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nvCXvXq5mP7p"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist      #importing libraries to have capabilities\n",
        "import numpy as np\n",
        "np.random.seed(1337)\n",
        "import pandas\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1GTR35cmP7v"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uQ_KjFJomP7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64db8bcc-b381-4e55-cd22-4bd8d781530f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()  #load available data online"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-Lw_bPQKQFX"
      },
      "source": [
        "## View the shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ueyWl-aUmP72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd95beb-f164-4584-ce8c-a6c50c32405d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape :  (60000, 28, 28) (60000,)\n",
            "Testing data shape :  (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "print('Training data shape : ', X_train.shape, Y_train.shape)   #shape of training data X and Y\n",
        "print('Testing data shape : ', X_test.shape, Y_test.shape)    #shape of testing data X and Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z51sdOntmP78"
      },
      "source": [
        "## Find the unique numbers from the train labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o29O_gUTmP79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d55e87c-0cf1-4bb3-f2cf-8256c9ed56bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of outputs :  10\n",
            "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ],
      "source": [
        "classes = np.unique(Y_train)\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMMjLgbimP8B"
      },
      "source": [
        "## Plot some of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qQpW4rajmP8C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "66a50c3c-2664-44e4-c713-56b03fad4971"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ground Truth : 7')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=[10,5])\n",
        " \n",
        "# Display the first image in training data\n",
        "plt.subplot(121)\n",
        "plt.imshow(X_train[0,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(Y_train[0]))\n",
        " \n",
        "# Display the first image in testing data\n",
        "plt.subplot(122)\n",
        "plt.imshow(X_test[0,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(Y_test[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PY8KLU-mP8H"
      },
      "source": [
        "## Flatten the data\n",
        "\n",
        "In this notebook we won't be making use of the data as \"images\" but rather as long vectors of length 784"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVo2Tj7smP8I"
      },
      "source": [
        "## This is what an example in the dataset looks like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EtB2Fh5emP8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98fd635-1b28-4333-c4ae-94f781d26de7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KCIx4MeZmP8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3253d791-a3d7-4b6e-a452-eb2e96fee56e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doXYy1uzKWjA"
      },
      "source": [
        "## Task: Convert from image shape to a vector shape\n",
        "\n",
        "We go from 28x28 pixel sized images to a vector of length 784.\n",
        "\n",
        "We would like to reshape the training data from shape (60000, 28, 28) to (60000,784). To do this, we can make use of Numpy's *reshape* function. \n",
        "\n",
        "Hint: ...reshape(...).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vQ70mEZoV3I-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e0fd10-16a1-4d29-a559-b3b1353b4df8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kIZeZeP5mP8R"
      },
      "outputs": [],
      "source": [
        "num_pixels = X_train.shape[1] * X_train.shape[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "C5f0gLa8Vsj_"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (60000,784))\n",
        "X_test = np.reshape(X_test, (10000,784))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAvNzShjmP8U"
      },
      "source": [
        "## Now the data is a long vector\n",
        "\n",
        "There are 60,000 examples for which each is a vector of length 784"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yQW62Xe0mP8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecaec97d-be85-4dee-8f72-6ec729e57fb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPx7o41CK2S-"
      },
      "source": [
        "## View the first example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PzXHvbF0nCaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fd0e42-fdc6-49ca-9a72-9031edd1b639"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg8TnPhpRpb8",
        "outputId": "12829997-a4a0-48df-d32d-ef1c5145137a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YNkeCMoUmP8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b0013bc-d879-4e73-c70c-3342c0a7ef8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
              "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
              "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
              "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
              "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
              "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
              "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
              "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
              "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
              "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BykRwF2UmP8b"
      },
      "source": [
        "## Task: Normalise\n",
        "\n",
        "We need to normalise the data since the values range from 0 to 255. Training NNs on data ranging between [0,1] can be easier. To do this, we simply divide by the maximum value, in this case 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FH2lcHF3mP8c"
      },
      "outputs": [],
      "source": [
        "X_train =(X_train)/255  #normalise trained x values\n",
        "X_test = (X_test)/255   #normalise test x values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj0QhPSsmP8e"
      },
      "source": [
        "## One hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQWHZ6FumP8f"
      },
      "source": [
        "We're going to want our labels as one-hot vectors, which are vectors that holds mostly 0's and one 1. It's easiest to see this in a example. As a one-hot vector, the number 0 is represented as [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], and 4 is represented as [0, 0, 0, 0, 1, 0, 0, 0, 0, 0].\n",
        "\n",
        "One-hot encoded vectors allow us to map each category in our set of labels to a vector where only a single value is 1.\n",
        "\n",
        "0 maps to [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "1 maps to [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "2 maps to [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "Notes on one-hot encoding: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGRXrRTYmP8g"
      },
      "source": [
        "## Before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wrKyI7DamP8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d5fa36-a44b-47cd-e7bb-a2ae8af0127d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "Y_test[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfClFp-6K7P6"
      },
      "source": [
        "## Task: Convert from categorical labels to one-hot encoded vectors\n",
        "\n",
        "In this case there are 10 classes so we can tell the function to convert into a vector of length 10. You need to convert both the training targets and the testing targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "i3xjsPnVmP8j"
      },
      "outputs": [],
      "source": [
        "Y_train=np_utils.to_categorical(Y_train)# Your code here\n",
        "Y_test=np_utils.to_categorical(Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92H9U6LkmP8m"
      },
      "source": [
        "## After"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tiiXZrnUmP8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb36c500-1e8e-45f4-ce0b-c071857b8a6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "Y_test[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VungsdeHmP8u"
      },
      "source": [
        "## Task: Create a neural network model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gozmsPxhmP8v"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "def baseline():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # add one fully connected layer\n",
        "    model.add(Dense(15, input_dim=784, activation='relu'))\n",
        "    # add a fully connected layer for the output\n",
        "    model.add(Dense(13,activation='relu'))\n",
        "    model.add(Dense(10,activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_aNPZE0W2V9"
      },
      "source": [
        "## Task: Initialise the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Q03EcUrxmP8x"
      },
      "outputs": [],
      "source": [
        "model=baseline()# Nueral network model initialised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUN6K31smP80"
      },
      "source": [
        "## Task: Determine the number of trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_DxDanOHmP80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be43b92-323e-450b-8ce6-377036ec7851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 15)                11775     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13)                208       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                140       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,123\n",
            "Trainable params: 12,123\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()# summary of trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmezlwQyRpdI",
        "outputId": "acff791e-e535-47be-b8a7-dd0224228de1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X_train.shape   # we check shape for consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OINoVTCtRpdK",
        "outputId": "fdcaa1cb-c493-4443-91eb-24eec126e44b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "Y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqFCIt_0RpdN",
        "outputId": "a4e1da46-4d80-49f8-e756-64bee4878c6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cLAWseMRpdR",
        "outputId": "f9f569f4-3134-4942-ed98-c7678f22a1f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ie1j6BFgRpdT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifPs0mftmP84"
      },
      "source": [
        "## Task: Begin training\n",
        "\n",
        "Fit on the training features and targets. Also make use of the validation data you've set aside above. Set the number of epochs, batch size and also explore various *verbose* values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "j8RZc1rhmP84"
      },
      "outputs": [],
      "source": [
        "X_train,X_val,Y_train,Y_val=train_test_split(X_train,Y_train,test_size=0.3)# we split data into test, train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olhfDjjxRpdY",
        "outputId": "f0595746-3545-42d8-a5d8-4608ff45bcfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10500/10500 [==============================] - 25s 2ms/step - loss: 0.4108 - accuracy: 0.8764 - val_loss: 0.2939 - val_accuracy: 0.9150\n",
            "Epoch 2/20\n",
            "10500/10500 [==============================] - 22s 2ms/step - loss: 0.2449 - accuracy: 0.9289 - val_loss: 0.2319 - val_accuracy: 0.9321\n",
            "Epoch 3/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.2145 - accuracy: 0.9358 - val_loss: 0.2233 - val_accuracy: 0.9367\n",
            "Epoch 4/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1945 - accuracy: 0.9425 - val_loss: 0.2228 - val_accuracy: 0.9387\n",
            "Epoch 5/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1811 - accuracy: 0.9468 - val_loss: 0.2144 - val_accuracy: 0.9398\n",
            "Epoch 6/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1720 - accuracy: 0.9488 - val_loss: 0.2172 - val_accuracy: 0.9401\n",
            "Epoch 7/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1632 - accuracy: 0.9524 - val_loss: 0.2213 - val_accuracy: 0.9377\n",
            "Epoch 8/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1591 - accuracy: 0.9527 - val_loss: 0.2174 - val_accuracy: 0.9391\n",
            "Epoch 9/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1534 - accuracy: 0.9554 - val_loss: 0.2194 - val_accuracy: 0.9380\n",
            "Epoch 10/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1485 - accuracy: 0.9549 - val_loss: 0.2216 - val_accuracy: 0.9407\n",
            "Epoch 11/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1450 - accuracy: 0.9563 - val_loss: 0.2166 - val_accuracy: 0.9407\n",
            "Epoch 12/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1411 - accuracy: 0.9571 - val_loss: 0.2178 - val_accuracy: 0.9391\n",
            "Epoch 13/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1385 - accuracy: 0.9585 - val_loss: 0.2172 - val_accuracy: 0.9428\n",
            "Epoch 14/20\n",
            "10500/10500 [==============================] - 22s 2ms/step - loss: 0.1359 - accuracy: 0.9590 - val_loss: 0.2103 - val_accuracy: 0.9420\n",
            "Epoch 15/20\n",
            "10500/10500 [==============================] - 22s 2ms/step - loss: 0.1339 - accuracy: 0.9603 - val_loss: 0.2115 - val_accuracy: 0.9430\n",
            "Epoch 16/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1305 - accuracy: 0.9616 - val_loss: 0.2187 - val_accuracy: 0.9423\n",
            "Epoch 17/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1285 - accuracy: 0.9606 - val_loss: 0.2308 - val_accuracy: 0.9397\n",
            "Epoch 18/20\n",
            "10500/10500 [==============================] - 24s 2ms/step - loss: 0.1282 - accuracy: 0.9616 - val_loss: 0.2225 - val_accuracy: 0.9418\n",
            "Epoch 19/20\n",
            "10500/10500 [==============================] - 24s 2ms/step - loss: 0.1257 - accuracy: 0.9611 - val_loss: 0.2286 - val_accuracy: 0.9402\n",
            "Epoch 20/20\n",
            "10500/10500 [==============================] - 23s 2ms/step - loss: 0.1218 - accuracy: 0.9618 - val_loss: 0.2261 - val_accuracy: 0.9417\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(X_train,Y_train,validation_data=(X_val,Y_val),epochs=20,batch_size=4,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j9LecHgmP8_"
      },
      "source": [
        "## Task: Predict on the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7TtfkDWjmP8_"
      },
      "outputs": [],
      "source": [
        "prediction=model.predict(X_test)# we make prediction using our trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1yqU_ijORpdg"
      },
      "outputs": [],
      "source": [
        "prediction_classes=np.argmax(prediction,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo4UgmBvmP9F"
      },
      "source": [
        "## Task: Compute the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "N7keRohxmP9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb33ffc-df07-4263-f43a-88e93fc66d1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9478"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "accuracy_score(np.argmax(Y_test,1),prediction_classes)# we check error of our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5K0VcsKpRpdr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "leon_Tensorflow_Classification_Practical3_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}